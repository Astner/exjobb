\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09


\usepackage[pdftex]{graphicx}
\graphicspath{{./graphics}}
\DeclareGraphicsExtensions{.pdf}
\usepackage[cmex10]{amsmath}
\usepackage{algorithm, algorithmic}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{mdwtab}
\usepackage{eqparbox}
\usepackage{bm}
\usepackage{stfloats}
\usepackage{url}
\usepackage{marginnote}
\usepackage{mathtools}

\title{Analogy Discovery from Data}

\author{
Daniel Gillblad, Olof G\"{o}rnerup, Theodore Vasiloudis \\
Decisions, Networks and Analytics Laboratory\\
Swedish Institute of Computer Science\\
\texttt{\{dgi, olof, tvas\}@sics.se}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% For commenting
\newcommand{\comment}[1]{{\small \color{red} {#1}} \normalcolor}
% Use this line for leaving out comments
%\newcommand{\comment}[1]{}

% Notation commands (change all by changing here)
% Capital rho
\newcommand{\Rho}{\mathrm{P}}
% Concept relation
\newcommand{\rn}[1]{\rho_{#1}}
% Concept L1 norm
\newcommand{\rns}[1]{|\rn{#1}|_1}
% Concept relation threshold
\newcommand{\mrn}[1]{\tau_{#1}}
% Discarded concept relation sum
\newcommand{\drns}[1]{|\check{\rho}_{#1}|_1}
% Kept concept relation sum
\newcommand{\krns}[1]{|\hat{\rho}_{#1}|_1}
% Concept relation vector
\newcommand{\rv}{\Rho}
% Concept similarity
\newcommand{\sy}[1]{\sigma_{#1}}
% Approximate concept similarity
\newcommand{\asy}[1]{\tilde{\sigma}_{#1}}
% L1 norm of difference
\newcommand{\nm}[1]{L_1(#1)}
\newcommand{\dnm}[2]{|\rn{#1}-\rn{#2}|_1}
% Approximate L_1 norm
\newcommand{\anm}[1]{\tilde{L}_1(#1)}
% Common context
\newcommand{\ccn}[1]{\chi_{#1}}
% Edge graph
\newcommand{\egr}[1]{\eta_{#1}}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Analogies, or similarities between object relations, represent a fundamental tool for reasoning and knowledge 
representation. Here, we show that the typical vector arithmetics approach proposed for finding analogous relations lead to 
false positives. \comment{It will be important if we can show that our model supports polysemy, which vectors inherently lack. 
e.g. can only have one vector for apple, how can we discern between company/fruit? Olof: This is a general shortcoming that we
need to adress. If we solve this, the solution can certainly be presented in a separate paper. One possible way to go about is to first 
partition the correlation graph using community detection (e.g. all computer related terms in one cluster and all food related stuff in one
cluster), and then split an ambiguous word, such as apple, into two versions, apple$_1$ and apple$_2$, if it is strongly correlated to
two separate clusters that are, by definition, weakly interlinked. Whether this would work or not is speculation of course.}
We propose an object relation similarity measure that does not suffer from these shortcomings, and can be 
used for analogy discovery at scale.
\end{abstract}

\section{Introduction}

We would like to find analogies such as \emph{Paris relates to France as Berlin relates to Germany}. In the following, we 
will write the analogy ``$a$ is to $b$ as $c$ is to $d$'' as
\begin{equation}
a : b :: c : d
\end{equation}

\section{Related work}
Vector arithmetic has been used in the literature to relate word relations, where vector representations
of words are generated by a recurrent neural network \cite{Mikolov2013}. For example, if
$p$ relates to $f$ as $b$ relates to $g$, it is argued that $v_{p} - v_{f} \approx v_{b} - v_{g}$, where $v_i$ are
vectors.

\section{Preliminaries}
\label{sec:preliminaries}

Let $C = \{i\}_{i=1}^n$ be a set of \emph{objects} (that may be concepts), where each object has a
correlation, $\rn{i,j}$, to each other object. The \emph{context} of an object $i$ is defined to be its
vector of relations to every other object, $\rn{i} = (\rn{i,j})_{j=1}^n$. The \emph{similarity}, $\sy{i,j}$, between
objects $i$ and $j$ is defined to be 1 subtracted by the relative $L_1$-norm of the difference between $\rn{i}$ and $\rn{j}$:
\begin{equation}\label{eq:sim}
\sy{i,j} = 1 - \frac{\dnm{i}{j}}{\rns{i} + \rns{j}},
\end{equation}
where $\rns{i} + \rns{j}$ is the maximum possible norm of the difference between $\rns{i}$ and $\rns{j}$.

\section{Methods}

\subsection{Comparing context vectors}
Similarly to the approach presented by Mikolov et al.\ \cite{Mikolov2013}, is it possible to discover analogous
object relations by comparing the differences between their respective correlation vectors?
Consider four objects $a$, $b$, $c$ and $d$ and the analogy $a : b :: c : d$. Then
\begin{equation}\label{}
\rn{a} - \rn{b} \approx \rn{c} - \rn{d} \Leftrightarrow |\rn{a} - \rn{b} - (\rn{c} - \rn{d})| < \epsilon,
\end{equation}
for some small value $\epsilon$. Further,
\begin{eqnarray}\label{eq:inequality}
|\rn{a} - \rn{b} - (\rn{c} - \rn{d})| \leq |\rn{a} - \rn{b}| + |\rn{d} - \rn{c}|
\end{eqnarray}
due to the triangle inequality. The right hand side of Eq.\ \ref{eq:inequality} is small if both $\sy{a,b}$ and $\sy{c,d}$
are close to 1, which in turn implies that if $a$ is similar to $b$ and $c$ is similar to $d$, then \emph{$a$ is related to $b$
	as $c$ is related to $d$}. However, this is clearly not always the case (consider for instance the statement \emph{Nebraska relates to
	Kansas as birthday relates to anniversary}). From this we can conclude that it is not sufficient to discover
analogies by comparing distances between raw correlation vectors.

\subsection{Edge graph similarity}

To arrive at a usable expression, we return to the dictionary definition of analogy as ``agreement or similarity, [esp.] in a certain limited number of features or details'' \cite{makins1991collins}.

Consider again the four objects $a$, $b$, $c$ and $d$ and the analogy $a : b :: c : d$. To determine whether this is a valid 
analogy or not, we consider
\begin{enumerate}
	\item{What do $a$ and $c$ have in common?}
	\item{What do $b$ and $d$ have in common?}
	\item{In the context of these commonalities, does $a$ relate to $b$ as $c$ to $d$?}
\end{enumerate}
The first two points can be viewed as finding the common context between objects, and the last point can be formulated as a 
similarity between vertices in an edge graph created from the correlation graph.

Define the \emph{common context} of objects $i$ and $j$ as
\begin{equation}
\ccn{ij} = \rn{i} \circ \rn{j},
\end{equation}
that is the element-wise product of the context vectors $\rn{i}$ and $\rn{j}$. \comment{Olof: Need to handle negative correlations
here. Alternatively use element-wise similarity based on the relative L$_1$-norm as in Eq.\ \ref{eq:sim}?} The resulting vector will put relative 
emphasis on correlations to objects $k$ were both $\rn{i,k}$ and $\rn{j,k}$ are strong.

As outlined above, we can now express a valid analogy as
\begin{eqnarray}
\ccn{ac} \circ \rn{a} - \ccn{bd} \circ \rn{b} \approx \ccn{ac} \circ \rn{c} - \ccn{bd} \circ \rn{d}
& \Leftrightarrow &  \nonumber\\
\label{eq:analogydiv}
| \ccn{ac} \circ (\rn{a} - \rn{c}) - \ccn{bd} \circ (\rn{b} - \rn{d}) | & < & \epsilon
\end{eqnarray}
for some small value $\epsilon$. Essentially, equation \ref{eq:analogydiv} describes a divergence measure which is (close 
to) zero for valid analogies and increases the less relevant the analogy is. If we let
\begin{equation}
\label{eq:edgegraph}
\egr{ij} = \ccn{ij} \circ (\rn{i} - \rn{j})
\end{equation}
define edge graph vertices, this divergence measure can be written as
\begin{equation}
\Delta_{ac,bd} = | \egr{ac} - \egr{bd} |
\end{equation}
and we can define the validity (strength) of an analogy as an \emph{edge graph similarity} in the same manner as between 
objects,
\begin{equation}\label{eq:analogy}
\alpha_{ij,kl} = 1 - \frac{|{\egr{ij} - \egr{kl}}|_1}{|\egr{ij}|_1 + |\egr{kl}|_1},
\end{equation}

Thus, to calculate all relevant analogies $\alpha_{ij,kl}$, we
\begin{enumerate}
	\item{Expand the correlation graph $\rn{i,j}$ to an edge graph $\egr{ij}$ using Eq. \ref{eq:edgegraph}}
	\item{Based on this edge graph, all relevant calculate similarities using the methods described in \cite{gornerup2015similarity}}
\end{enumerate}

\section{Experiments}

\comment{For a strong paper we need again multidisciplinary experiments. The good thing is that this time
	we will have standardized benchmarks for analogies to include if we get good results. For 
	qualitative it would be cool if we can discover cool music artist analogies, but what would those be?}

\section{Conclusions}

\bibliographystyle{IEEEtran}
\bibliography{analogies-nips2016}

\end{document}
